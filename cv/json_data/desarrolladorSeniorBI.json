[
  {
    "nombre": "Alma Rebeca Ibañez Carranza",
    "rol_propuesto": "Desarrollador Senior BI",
    "resumen_profesional": "Especializada en gestión y modelado de datos orientada al diseño y construcción de procesos ETL para entornos financieros.\nCon experiencia en mapeos origen-destino, definición de reglas de negocio y diseño de modelos conceptuales y lógicos.\nEnfocada en asegurar la calidad y trazabilidad del dato mediante pruebas, validaciones y documentación técnica.\nAplica metodologías ágiles para coordinar entregables, soporte a producción y explotación de datos para KPIs.\n\nCapaz de integrar soluciones con herramientas como SAS y Microsoft SQL Server, manteniendo consistencia en esquemas y flujos de proceso.\nParticipa en la generación de diagramas de flujo, catálogos de reglas y manuales de operación para facilitar la transferencia de conocimiento.\nContribuye al análisis de fuentes de datos y al diseño de componentes reutilizables orientados a la optimización de procesos ETL.\nAporta liderazgo técnico en la comunicación con usuarios de negocio y en la entrega de soluciones alineadas a necesidades analíticas.",
    "experiencia_laboral": [
      {
        "empresa": "Softtek",
        "puesto": "Data Management Engineer OnPrem ETL Sr",
        "fecha_inicio": "mayo 2018",
        "fecha_fin": "Current",
        "actividades_principales": [
          "Identificar requerimientos con usuarios de negocio para elaborar documentos de análisis",
          "Elaborar catálogos de reglas de negocio y diagramas de contexto",
          "Analizar fuentes de datos y mapear estructuras de origen",
          "Diseñar modelos conceptuales y lógicos de datos",
          "Elaborar mapeos origen-destino e identificar transformaciones tecnológicas",
          "Generar esquemas de flujo y diagramas para procesos analizados",
          "Definir especificaciones técnicas y casos de prueba para la construcción e integración de la solución",
          "Construir soluciones ETL utilizando SAS Data Integration y otras tecnologías",
          "Realizar pruebas unitarias y actividades de aseguramiento de calidad de los entregables",
          "Soportar modelos de datos para su explotación en herramientas front-end y validar KPIs con SQL Developer"
        ]
      }
    ],
    "ajuste_puesto_liderazgo": {
      "empresa": "Capgemini",
      "puesto": "Consultor SAS",
      "fecha_inicio": "May 2012",
      "fecha_fin": "May 2018",
      "actividades_principales": [
        "Realizar análisis y administración de datos para banca",
        "Apoyar en proyectos de experiencia de cliente",
        "Diseñar y construir soluciones con herramientas SAS para detección de puntos de compromiso",
        "Impartir entrenamiento en el uso de herramientas SAS al personal del cliente",
        "Desarrollar aplicaciones para reportes regulatorios y brindar soporte"
      ]
    },
    "periodo_resumen_laboral": "La experiencia abarca desde mayo de 2007 hasta mayo de 2018",
    "resumen_laboral": "Durante este período se desempeñaron funciones como Consultor SAS y Consultor Jr, con responsabilidades centradas en el análisis y la administración de datos para el sector financiero y de seguros. Las labores incluyeron diseño y construcción de soluciones para prevención de fraude y reportes regulatorios, apoyo en estudios de experiencia de cliente, capacitación de personal en herramientas SAS y soporte en la resolución de incidencias y procesos de datos.",
    "estudios": {
      "carrera": "Máster en Big Data y Business Analysis",
      "lugar": "Universidad Camilo JOSÉ Cela / IMF SMAT Educa",
      "periodo": "Feb 2019 - Feb 2022"
    },
    "certificaciones_y_cursos": [
      {
        "nombre": "Certificación Developer, Dataiku Academy",
        "anio": "2024"
      },
      {
        "nombre": "Certificación Advance Designer, Dataiku Academy",
        "anio": "2024"
      },
      {
        "nombre": "Certificado Core Designer, Dataiku Academy",
        "anio": "2024"
      },
      {
        "nombre": "Badge 3 Data Aplication Builders Workshop, Snowflake Academy",
        "anio": "2024"
      },
      {
        "nombre": "Badge2 Collaboration, Marketplace & Cost Estim, Snowflake Academy",
        "anio": "2024"
      },
      {
        "nombre": "Badge1 Data Warehousing Workshop, Snowflake Academy",
        "anio": "2024"
      },
      {
        "nombre": "Microsoft Certified: Azure Data Engineer - Asso, Microsoft",
        "anio": "2024"
      },
      {
        "nombre": "Certificación Liderazgo Orientado a Equipos, Softtek",
        "anio": "2023"
      },
      {
        "nombre": "Certificación Liderazgo Orientado a las Personas, Softtek",
        "anio": "2022"
      }
    ]
  },
  {
    "nombre": "Antonio Garcia Torres",
    "rol_propuesto": "Desarrollador Senior BI",
    "resumen_profesional": "Amplia trayectoria en diseño y desarrollo de soluciones de datos y procesos ETL para entornos on-premise y cloud.\nExperiencia en integración de fuentes heterogéneas, modelado dimensional y construcción de data lakes y datamarts.\nDominio de herramientas como IBM DataStage, Azure Data Factory, Databricks y plataformas de bases de datos relacionales.\nCapacidad para documentar orígenes de datos, definir reglas de negocio y optimizar procesos para soporte analítico.\n\nHistorial de liderazgo técnico en proyectos de BI, coordinación de equipos multidisciplinarios y gestión de migraciones de plataformas analíticas.\nEnfoque en garantizar calidad de datos, rendimiento de procesos ETL y entrega de indicadores para la toma de decisiones.\nSólida experiencia en generación de reportes y dashboards con Power BI y en la migración de soluciones desde QlikView.\nOrientación a la mejora continua mediante pruebas de concepto y adopción de arquitecturas escalables.",
    "experiencia_laboral": [
      {
        "empresa": "AXA",
        "puesto": "Data Analyst",
        "fecha_inicio": "agosto 2025",
        "fecha_fin": "noviembre 2025",
        "actividades_principales": [
          "Analizar orígenes de datos para la migración de los sistemas de productos vida al nuevo modelo operativo.",
          "Diseñar el DataLake para el nuevo modelo operativo."
        ]
      },
      {
        "empresa": "Walmart",
        "puesto": "Arquitecto de Datos",
        "fecha_inicio": "diciembre 2024",
        "fecha_fin": "febrero 2025",
        "actividades_principales": [
          "Diseñar la arquitectura de datos para los procesos de cálculo de bono, analizando fuentes y reglas de negocio.",
          "Documentar orígenes de datos y relaciones entre fuentes y procesos para la provisión del bono."
        ]
      },
      {
        "empresa": "Citi",
        "puesto": "Modelador",
        "fecha_inicio": "2023",
        "fecha_fin": "2024",
        "actividades_principales": [
          "Modelar en capa semántica modelos tipo estrella y analizar reglas de negocio para indicadores financieros.",
          "Construir modelos en Erwin y generar DDLs de modelos estrella en Teradata."
        ]
      },
      {
        "empresa": "Nacional Monte De Piedad",
        "puesto": "Desarrollo de Procesos ETL en Azure Data Factory y Databricks",
        "fecha_inicio": "jun 2022",
        "fecha_fin": "jul 2022",
        "actividades_principales": [
          "Desarrollar procesos ETL en Azure Data Factory y Databricks para préstamos prendarios consumiendo información desde Blob Storage."
        ]
      },
      {
        "empresa": "COPPEL",
        "puesto": "Desarrollos de Procesos ETL en DataStage",
        "fecha_inicio": "junio 2021",
        "fecha_fin": "septiembre 2021",
        "actividades_principales": [
          "Desarrollar procesos ETL en DataStage 11.7, SQL Server y Postgres para migración de cartera a nuevo repositorio."
        ]
      },
      {
        "empresa": "Liverpool (PoC)",
        "puesto": "Desarrollo de Pruebas de Concepto de Integración de Información",
        "fecha_inicio": "marzo 2020",
        "fecha_fin": "abril 2020",
        "actividades_principales": [
          "Desarrollar pruebas de concepto de integración de información de la cadena de suministro para entrega de datos analíticos y transaccionales."
        ]
      },
      {
        "empresa": "BANOBRAS",
        "puesto": "Desarrollador ODI",
        "fecha_inicio": "septiembre 2019",
        "fecha_fin": "abril 2020",
        "actividades_principales": [
          "Diseñar modelos de datos en Oracle 12c y construir procesos ELT en ODI 12c para flujos de Mercados."
        ]
      },
      {
        "empresa": "UANL Centro De Desarrollo Mexico",
        "puesto": "Líder de Proyecto",
        "fecha_inicio": "septiembre 2010",
        "fecha_fin": "junio 2019",
        "actividades_principales": [
          "Administrar proyectos de BI y coordinar equipos para la migración de información entre sistemas legados y nueva plataforma."
        ]
      }
    ],
    "ajuste_puesto_liderazgo": {
      "empresa": "",
      "puesto": "",
      "fecha_inicio": "",
      "fecha_fin": "",
      "actividades_principales": []
    },
    "periodo_resumen_laboral": "La experiencia abarca desde septiembre de 2003 hasta septiembre de 2010",
    "resumen_laboral": "Durante este período se desempeñaron funciones como Gerente de Infraestructura, Consultor DataStage y Desarrollador DataStage, asumiendo responsabilidades en administración de plataformas, gestión de servicios contratados y desarrollo de procesos ETL. Se trabajó en diseño y mantenimiento de datamarts y sistemas web, soporte a procesos de negocio y generación de reportes de gestión para la toma de decisiones. Las tareas incluyeron coordinación técnica con proveedores y gestión operativa de infraestructuras.",
    "estudios": {
      "carrera": "Ingeniero en Computación",
      "lugar": "Instituto Politécnico Nacional",
      "periodo": "septiembre 1991 - junio 1995"
    },
    "certificaciones_y_cursos": [
      {
        "nombre": "Scrum Fundamentals Certified",
        "anio": "2022"
      },
      {
        "nombre": "Cloud Data Governance and Catalog (CDGC) Fundation Series Certification",
        "anio": ""
      },
      {
        "nombre": "Data Engineering Foundation 2023_2024 Knowledge Check - Module 1_ Data Architecture",
        "anio": ""
      },
      {
        "nombre": "Data Engineering Foundation 2023_2024 Knowledge Check - Module 2_ Data Ingestion",
        "anio": ""
      },
      {
        "nombre": "Data Engineering Foundation 2023_2024 Knowledge Check - Module 3_ Data Integration",
        "anio": ""
      },
      {
        "nombre": "Data Engineering Foundation 2023_2024 Knowledge Check - Module 4_ Advanced Data",
        "anio": ""
      },
      {
        "nombre": "NLP_Natural_Language_Processing_with_Python",
        "anio": ""
      },
      {
        "nombre": "Python_3_Deep_Dive_Part_1_Functional",
        "anio": ""
      },
      {
        "nombre": "Python_3_Deep_Dive_Part_2_Iterators_Generators",
        "anio": ""
      },
      {
        "nombre": "Python_3_Deep_Dive_Part_3_Dictionaries_Sets_Json",
        "anio": ""
      },
      {
        "nombre": "The_Complete_Python_Bootcamp_From_Zero_to_Hero_in_Python",
        "anio": ""
      }
    ]
  },
  {
    "nombre": "Claudio Roberto Diaz Mandujano",
    "rol_propuesto": "Desarrollador Senior BI",
    "resumen_profesional": "Posee más de 22 años de experiencia en integración de datos y construcción de procesos ETL en entornos on-premise y cloud.\nEspecializado en el diseño y mantenimiento de pipelines ETL, modelado multidimensional y documentación técnica detallada.\nResponsable de liderar equipos técnicos, coordinar entregas y asegurar la calidad y trazabilidad de los datos mediante runbooks y validaciones.\nOrientado a consolidar soluciones que soporten la explotación analítica y la transferencia de conocimiento entre equipos.\n\nConocimiento en herramientas como Informatica PowerCenter, IBM InfoSphere DataStage, Oracle PL/SQL y Oracle Data Integrator.\nDocumentación y catalogación de artefactos en AWS Glue, Glue Data Catalog y Amazon Athena, y traducción de consultas entre motores SQL.\nUso de Python y librerías como Pandas para perfilamiento, limpieza y matching de datos, además de scripts de automatización en Linux.\nExperiencia en despliegue y operación de jobs ETL en ambientes UAT y productivo, con monitoreo y gestión de incidentes.",
    "experiencia_laboral": [
      {
        "empresa": "Softtek - FashionPhile",
        "puesto": "Data Management Engineer Senior",
        "fecha_inicio": "febrero 2025",
        "fecha_fin": "noviembre 2025",
        "actividades_principales": [
          "Documentar artefactos desarrollados en AWS Glue y registrar metadatos en Glue Data Catalog y Amazon Athena",
          "Revisar y mejorar el modelo de datos multidimensional en Amazon RedShift"
        ]
      },
      {
        "empresa": "Softtek - Citi Banamex",
        "puesto": "Data Management Engineer OnPrem ETL Sr",
        "fecha_inicio": "octubre 2024",
        "fecha_fin": "enero 2025",
        "actividades_principales": [
          "Realizar deploy y configuración de jobs de limpieza de datos de Informatica Cloud Data Quality en servidores Linux",
          "Atender incidentes de nivel 1 y revisar logs de Informática Cloud Data Quality para análisis de errores."
        ]
      },
      {
        "empresa": "Softtek - Nacional Monte De Piedad",
        "puesto": "Data Management Engineer - Expert",
        "fecha_inicio": "noviembre 2022",
        "fecha_fin": "marzo 2023",
        "actividades_principales": [
          "Diseñar y construir mapas ETL en Informatica PowerCenter para agregar nuevos indicadores y dimensiones.",
          "Elaborar documentación técnica, planes de instalación, requerimientos de prueba y pruebas unitarias."
        ]
      },
      {
        "empresa": "Softtek - Coppel",
        "puesto": "Data Management Engineer - Senior",
        "fecha_inicio": "septiembre 2022",
        "fecha_fin": "octubre 2022",
        "actividades_principales": [
          "Construir interfaces ETL en IBM InfoSphere DataStage y generar scripts SQL para validación"
        ]
      },
      {
        "empresa": "Softtek - MetLife MÉXICO",
        "puesto": "Data Management Engineer - Expert",
        "fecha_inicio": "noviembre 2021",
        "fecha_fin": "agosto 2022",
        "actividades_principales": [
          "Diseñar y construir interfaces ETL en Informática PowerCenter para procesos del proyecto regulatorio LDTI.",
          "Empaquetar componentes ETL y gestionar Change Requests en ServiceNow para liberaciones en UAT y producción."
        ]
      },
      {
        "empresa": "Softtek - IMSS",
        "puesto": "Data Management Engineer - Senior",
        "fecha_inicio": "septiembre 2020",
        "fecha_fin": "febrero 2021",
        "actividades_principales": [
          "Desarrollar el módulo de pareo (matching) en Python para identificar registros únicos y similares.",
          "Aplicar pruebas unitarias y de volumen al módulo de matching para validar desempeño y precisión."
        ]
      },
      {
        "empresa": "Softtek",
        "puesto": "Data Management Engineer - Senior",
        "fecha_inicio": "mayo 2020",
        "fecha_fin": "agosto 2020",
        "actividades_principales": [
          "Desarrollar módulos de perfilamiento, limpieza y estandarización de datos en Python usando Pandas"
        ]
      },
      {
        "empresa": "Softtek - Banobras",
        "puesto": "Data Management Engineer - Senior",
        "fecha_inicio": "agosto 2020",
        "fecha_fin": "abril 2021",
        "actividades_principales": [
          "Construir procesos ETL en Oracle Data Integrator para integración operativa y conciliaciones de mercados.",
          "Generar cuadros comparativos para conciliaciones y documentar procesos ETL y paquetes de ejecución."
        ]
      },
      {
        "empresa": "Softtek - Seguros Banorte",
        "puesto": "Data Management Engineer - Expert",
        "fecha_inicio": "junio 2019",
        "fecha_fin": "agosto 2019",
        "actividades_principales": [
          "Diseñar y construir procesos ETL en Informatica PowerCenter para la migración de información hacia Acsel/x.",
          "Elaborar documentación técnica de las interfaces ETL relacionadas con recibos, pólizas y movimientos."
        ]
      },
      {
        "empresa": "Softtek - MetLife Argentina",
        "puesto": "Data Management Engineer - Expert",
        "fecha_inicio": "noviembre 2018",
        "fecha_fin": "mayo 2019",
        "actividades_principales": [
          "Soportar y mantener interfaces ETL en Informatica PowerCenter para generación de archivos hacia Big Data.",
          "Elaborar documentación técnica y ejecutar pruebas unitarias de las interfaces mantenidas."
        ]
      }
    ],
    "ajuste_puesto_liderazgo": {
      "empresa": "",
      "puesto": "",
      "fecha_inicio": "",
      "fecha_fin": "",
      "actividades_principales": []
    },
    "periodo_resumen_laboral": "La experiencia abarca desde noviembre de 1997 hasta octubre de 2018",
    "resumen_laboral": "Durante este período se desempeñaron funciones como Software Engineer, Technical Leader y Data Management Engineer en proyectos de integración, migración y calidad de datos. Las responsabilidades incluyeron diseño y mantenimiento de procesos ETL, generación de documentación técnica, capacitación y transferencia de conocimiento, así como soporte a producción y coordinación técnica de equipos de trabajo.",
    "estudios": {
      "carrera": "Licenciatura en INFORMÁTICA Administrativa",
      "lugar": "Universidad Tecnológica de México",
      "periodo": "enero 1994 - diciembre 1998"
    },
    "certificaciones_y_cursos": [
      {
        "nombre": "Cloud Particioner Essentials",
        "anio": ""
      },
      {
        "nombre": "Cloud_Data_Integration_PC",
        "anio": ""
      },
      {
        "nombre": "Data Engineer on AWS - Batch",
        "anio": ""
      },
      {
        "nombre": "Data Engineer on AWS - Data warehouse",
        "anio": ""
      },
      {
        "nombre": "Data Engineer on AWS - Foundations",
        "anio": ""
      },
      {
        "nombre": "Data Engineer on AWS - Streaming",
        "anio": ""
      },
      {
        "nombre": "Databricks Fundamentals Analyzing Data with Python",
        "anio": "2020"
      },
      {
        "nombre": "Fundamentos de Python",
        "anio": "2024"
      }
    ]
  }
]
